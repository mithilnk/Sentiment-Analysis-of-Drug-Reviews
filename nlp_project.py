# -*- coding: utf-8 -*-
"""NLP Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dhKWSUd516H5lSUkZCoU4gIpdHoerMvC

NLP Project by Mithil Khadye
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

df = pd.read_table("drugLibTest_raw.tsv")
df.head()

df.info()

df.isnull().sum()

df["commentsReview"]

df["commentsReview"][0]

df["label"]=["pos" if i >=6 else "neg" for i in df["rating"].values]

df

df.label.value_counts()

from wordcloud import WordCloud

wc=WordCloud(width=1000, height=800)
wc.generate(" ".join(df[df["label"]=="pos"]["commentsReview"]))
plt.imshow(wc)
plt.axis("off")
plt.show()

wc=WordCloud(width=1000, height=800, background_color="white")
wc.generate(" ".join(df[df["label"]=="neg"]["commentsReview"]))
plt.imshow(wc)
plt.axis("off")
plt.show()

import nltk

from nltk.tokenize import word_tokenize
nltk.download("punkt")

from nltk.corpus import stopwords
nltk.download("stopwords")

from nltk.stem import WordNetLemmatizer
nltk.download("wordnet")

lemma = WordNetLemmatizer()

def cleantext(text):
  token=word_tokenize(text.lower())
  ftoken=[t for t in token if (t.isalpha())]

  stop=stopwords.words("english")
  ctoken=[t for t in ftoken if (t not in stop)]

  lemma=WordNetLemmatizer()
  ltoken=[lemma.lemmatize(t) for t in ctoken]

  return" ".join(ltoken)

df["commentsReview"].head()

df["commentsReview"]=df["commentsReview"].apply(cleantext)

df.head()

df[df['label']=='neg'].head()

x=df["commentsReview"]
y=df["label"]

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer()
x=cv.fit_transform(x).toarray()

pip install sklearn

from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import classification_report

from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.3, random_state=1)

def mymodel(model):
  model.fit(xtrain,ytrain)
  ypred=model.predict(xtest)
  print(classification_report(ytest,ypred))
  return model

lr = mymodel(LogisticRegression())

svc = mymodel(LinearSVC())

nb=mymodel(GaussianNB())

rf=mymodel(RandomForestClassifier())

def checksentiment(text):
  text=cleantext(text)
  new=cv.transform([text]).toarray()
  pred=lr.predict(new)[0]
  return pred

df.head(10)

smsg=df["commentsReview"][100]
hmsg=df["commentsReview"][50]

checksentiment(smsg)

checksentiment(hmsg)

checksentiment("this drug has bad reactions")

checksentiment("this drug results in improvement of health")

